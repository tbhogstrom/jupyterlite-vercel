{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Job Search Analytics\n",
    "\n",
    "This notebook demonstrates how to automate job market analysis using the Serper API and Python. We'll build a system to track job postings, analyze trends, and identify opportunities in the tech job market.\n",
    "\n",
    "## What You'll Learn\n",
    "- **API Integration** with Serper for job board searching\n",
    "- **Data deduplication** and trend analysis\n",
    "- **Automated tracking** of job application status\n",
    "- **Market intelligence** for job seekers\n",
    "\n",
    "Based on real job search automation used to track 600+ unique job postings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from datetime import datetime, timedelta\n",
    "from urllib.parse import urlparse\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"ðŸ” Job Search Analytics Environment Ready!\")\n",
    "print(\"ðŸ“Š Libraries loaded for market analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job Search Query Strategy\n",
    "\n",
    "Let's define strategic search queries for technical SEO and marketing roles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define job board sites and search queries\n",
    "job_boards = [\n",
    "    'site:myworkdayjobs.com',\n",
    "    'site:jobs.lever.co', \n",
    "    'site:boards.greenhouse.io',\n",
    "    'site:icims.com',\n",
    "    'site:ashbyhq.com',\n",
    "    'site:smartrecruiters.com'\n",
    "]\n",
    "\n",
    "base_sites = ' | '.join(job_boards)\n",
    "\n",
    "# Strategic search queries focusing on technical SEO + AI/ML\n",
    "search_queries = [\n",
    "    f'{base_sites} (\"Technical SEO\" OR \"SEO Manager\") AND remote',\n",
    "    f'{base_sites} (SEO AND \"Python\") AND remote',\n",
    "    f'{base_sites} (SEO AND \"machine learning\") AND remote',\n",
    "    f'{base_sites} (\"Content Strategy\" AND AI) AND remote',\n",
    "    f'{base_sites} (\"Growth Marketing\" AND SEO) AND remote'\n",
    "]\n",
    "\n",
    "print(\"ðŸŽ¯ Configured search strategy:\")\n",
    "print(f\"ðŸ“ Job boards: {len(job_boards)}\")\n",
    "print(f\"ðŸ” Search queries: {len(search_queries)}\")\n",
    "print(\"\\nExample query:\")\n",
    "print(search_queries[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulated Job Market Data\n",
    "\n",
    "Let's create realistic job posting data based on actual search results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate realistic job posting data\n",
    "np.random.seed(42)\n",
    "\n",
    "companies = [\n",
    "    'Stripe', 'Coinbase', 'Chime', 'DoorDash', 'Samsara', 'Elastic', 'ServiceNow',\n",
    "    'Atlassian', 'Fieldguide', 'Upwork', 'Flatfile', 'The Zebra', 'Abnormal Security'\n",
    "]\n",
    "\n",
    "job_titles = [\n",
    "    'Sr. SEO Manager', 'Technical SEO Specialist', 'Content Strategy Manager',\n",
    "    'Growth Marketing Manager', 'SEO Program Manager', 'Digital Marketing Manager',\n",
    "    'Marketing Analytics Manager', 'Content Marketing Lead'\n",
    "]\n",
    "\n",
    "job_boards_short = ['Greenhouse', 'Lever', 'SmartRecruiters', 'Ashby', 'Company Website']\n",
    "\n",
    "# Generate job postings over the last 7 days\n",
    "jobs_data = []\n",
    "base_date = datetime.now() - timedelta(days=7)\n",
    "\n",
    "for i in range(150):  # 150 job postings\n",
    "    post_date = base_date + timedelta(days=np.random.randint(0, 8))\n",
    "    \n",
    "    jobs_data.append({\n",
    "        'company': np.random.choice(companies),\n",
    "        'title': np.random.choice(job_titles),\n",
    "        'board': np.random.choice(job_boards_short),\n",
    "        'date_posted': post_date.strftime('%Y-%m-%d'),\n",
    "        'remote': np.random.choice(['Remote', 'Hybrid', 'On-site'], p=[0.7, 0.2, 0.1]),\n",
    "        'salary_range': f\"${np.random.randint(120, 200)}k - ${np.random.randint(200, 300)}k\",\n",
    "        'requires_python': np.random.choice([True, False], p=[0.3, 0.7]),\n",
    "        'requires_sql': np.random.choice([True, False], p=[0.4, 0.6]),\n",
    "        'ai_mentioned': np.random.choice([True, False], p=[0.25, 0.75])\n",
    "    })\n",
    "\n",
    "jobs_df = pd.DataFrame(jobs_data)\n",
    "jobs_df['date_posted'] = pd.to_datetime(jobs_df['date_posted'])\n",
    "\n",
    "print(f\"ðŸ“Š Generated {len(jobs_df)} job postings\")\n",
    "print(f\"ðŸ¢ Companies: {jobs_df['company'].nunique()}\")\n",
    "print(f\"ðŸ“… Date range: {jobs_df['date_posted'].min().date()} to {jobs_df['date_posted'].max().date()}\")\n",
    "\n",
    "jobs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job Market Trend Analysis\n",
    "\n",
    "Let's analyze posting trends and identify market patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily job posting trends\n",
    "daily_posts = jobs_df.groupby('date_posted').size().reset_index()\n",
    "daily_posts.columns = ['date', 'job_count']\n",
    "\n",
    "# Create trend visualization\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=daily_posts['date'],\n",
    "    y=daily_posts['job_count'],\n",
    "    mode='lines+markers',\n",
    "    name='Daily Job Postings',\n",
    "    line=dict(color='#2E86AB', width=3),\n",
    "    marker=dict(size=8, color='#F24236')\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Daily Job Posting Volume - SEO/Marketing Roles',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Number of Job Postings',\n",
    "    height=400,\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(f\"ðŸ“ˆ Average daily postings: {daily_posts['job_count'].mean():.1f}\")\n",
    "print(f\"ðŸ”¥ Peak posting day: {daily_posts.loc[daily_posts['job_count'].idxmax(), 'date'].strftime('%A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skills Demand Analysis\n",
    "\n",
    "Analyze which technical skills are most in-demand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skills demand analysis\n",
    "skills_summary = pd.DataFrame({\n",
    "    'Skill': ['Python', 'SQL', 'AI/ML'],\n",
    "    'Jobs_Requiring': [\n",
    "        jobs_df['requires_python'].sum(),\n",
    "        jobs_df['requires_sql'].sum(), \n",
    "        jobs_df['ai_mentioned'].sum()\n",
    "    ],\n",
    "    'Percentage': [\n",
    "        jobs_df['requires_python'].mean() * 100,\n",
    "        jobs_df['requires_sql'].mean() * 100,\n",
    "        jobs_df['ai_mentioned'].mean() * 100\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Create skills demand chart\n",
    "fig = px.bar(\n",
    "    skills_summary, \n",
    "    x='Skill', \n",
    "    y='Percentage',\n",
    "    title='Technical Skills Demand in SEO/Marketing Jobs',\n",
    "    labels={'Percentage': '% of Job Postings'},\n",
    "    color='Percentage',\n",
    "    color_continuous_scale='viridis'\n",
    ")\n",
    "\n",
    "fig.update_layout(height=400, showlegend=False)\n",
    "fig.show()\n",
    "\n",
    "print(\"ðŸ’¡ Key Insights:\")\n",
    "for _, row in skills_summary.iterrows():\n",
    "    print(f\"   â€¢ {row['Skill']}: {row['Percentage']:.1f}% of postings ({row['Jobs_Requiring']} jobs)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application Tracking Dashboard\n",
    "\n",
    "Let's create a personal application tracking system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample application tracking data\n",
    "applications = [\n",
    "    {'date': '2025-01-17', 'company': 'ServiceNow', 'position': 'Sr. Content Strategist', 'status': 'Applied', 'source': 'SmartRecruiters'},\n",
    "    {'date': '2025-01-17', 'company': 'Elastic', 'position': 'Sr. SEO Program Manager', 'status': 'Applied', 'source': 'Company Website'},\n",
    "    {'date': '2025-01-16', 'company': 'The Dyrt', 'position': 'Programmatic SEO Engineer', 'status': 'Applied', 'source': 'Company Website'},\n",
    "    {'date': '2025-01-15', 'company': 'Chime', 'position': 'Staff Data Analyst, Organic Growth', 'status': 'Applied', 'source': 'Company Website'},\n",
    "    {'date': '2025-01-14', 'company': 'Samsara', 'position': 'Senior Web Analyst', 'status': 'Applied', 'source': 'Company Website'},\n",
    "    {'date': '2025-01-14', 'company': 'DoorDash', 'position': 'Associate Manager, Paid Marketing', 'status': 'Applied', 'source': 'Company Website'},\n",
    "    {'date': '2025-01-13', 'company': 'Umpqua Bank', 'position': 'Digital Marketing Manager', 'status': 'Rejected', 'source': 'Company Website'},\n",
    "    {'date': '2025-01-11', 'company': 'Upwork', 'position': 'Sr. SEO Manager - Product Team', 'status': 'Applied', 'source': 'Greenhouse'},\n",
    "    {'date': '2025-01-15', 'company': 'Maisa.ai', 'position': 'AI + SEO', 'status': 'In Discussion', 'source': 'Direct'},\n",
    "    {'date': '2025-01-11', 'company': 'Interview Query', 'position': 'Technical Content Manager', 'status': 'Offer Declined', 'source': 'Direct'}\n",
    "]\n",
    "\n",
    "apps_df = pd.DataFrame(applications)\n",
    "apps_df['date'] = pd.to_datetime(apps_df['date'])\n",
    "\n",
    "# Application status summary\n",
    "status_counts = apps_df['status'].value_counts()\n",
    "\n",
    "# Create status pie chart\n",
    "fig = px.pie(\n",
    "    values=status_counts.values,\n",
    "    names=status_counts.index,\n",
    "    title='Application Status Distribution',\n",
    "    color_discrete_sequence=px.colors.qualitative.Set3\n",
    ")\n",
    "\n",
    "fig.update_layout(height=400)\n",
    "fig.show()\n",
    "\n",
    "print(\"ðŸ“‹ Application Summary:\")\n",
    "print(f\"   ðŸ“¨ Total applications: {len(apps_df)}\")\n",
    "print(f\"   ðŸ¢ Companies targeted: {apps_df['company'].nunique()}\")\n",
    "print(f\"   ðŸ“… Date range: {apps_df['date'].min().date()} to {apps_df['date'].max().date()}\")\n",
    "\n",
    "print(\"\\nðŸ“Š Status breakdown:\")\n",
    "for status, count in status_counts.items():\n",
    "    print(f\"   â€¢ {status}: {count} applications\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Market Intelligence Insights\n",
    "\n",
    "Generate actionable insights from job market data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Company hiring activity\n",
    "company_activity = jobs_df.groupby('company').agg({\n",
    "    'title': 'count',\n",
    "    'remote': lambda x: (x == 'Remote').sum(),\n",
    "    'requires_python': 'sum',\n",
    "    'ai_mentioned': 'sum'\n",
    "}).round(0)\n",
    "\n",
    "company_activity.columns = ['Total_Posts', 'Remote_Posts', 'Python_Required', 'AI_Mentioned']\n",
    "company_activity = company_activity.sort_values('Total_Posts', ascending=False).head(8)\n",
    "\n",
    "print(\"ðŸ¢ TOP HIRING COMPANIES:\")\n",
    "print(company_activity)\n",
    "\n",
    "# Job board performance\n",
    "board_performance = jobs_df['board'].value_counts()\n",
    "\n",
    "print(\"\\nðŸ“‹ JOB BOARD ACTIVITY:\")\n",
    "for board, count in board_performance.items():\n",
    "    percentage = count / len(jobs_df) * 100\n",
    "    print(f\"   â€¢ {board}: {count} postings ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated Opportunity Scoring\n",
    "\n",
    "Create a scoring system to prioritize job opportunities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create opportunity scoring function\n",
    "def calculate_opportunity_score(row):\n",
    "    score = 0\n",
    "    \n",
    "    # Remote work bonus\n",
    "    if row['remote'] == 'Remote':\n",
    "        score += 30\n",
    "    elif row['remote'] == 'Hybrid':\n",
    "        score += 15\n",
    "    \n",
    "    # Technical skills alignment\n",
    "    if row['requires_python']:\n",
    "        score += 25\n",
    "    if row['requires_sql']:\n",
    "        score += 20\n",
    "    if row['ai_mentioned']:\n",
    "        score += 30\n",
    "    \n",
    "    # Job title relevance\n",
    "    title_lower = row['title'].lower()\n",
    "    if 'senior' in title_lower or 'sr.' in title_lower:\n",
    "        score += 20\n",
    "    if 'technical' in title_lower:\n",
    "        score += 25\n",
    "    if 'strategy' in title_lower:\n",
    "        score += 15\n",
    "    \n",
    "    return min(score, 100)  # Cap at 100\n",
    "\n",
    "# Calculate scores for all jobs\n",
    "jobs_df['opportunity_score'] = jobs_df.apply(calculate_opportunity_score, axis=1)\n",
    "\n",
    "# Find top opportunities\n",
    "top_opportunities = jobs_df.nlargest(10, 'opportunity_score')[['company', 'title', 'remote', 'opportunity_score']]\n",
    "\n",
    "print(\"ðŸŽ¯ TOP OPPORTUNITIES (Ranked by fit):\")\n",
    "print(top_opportunities.to_string(index=False))\n",
    "\n",
    "# Score distribution\n",
    "avg_score = jobs_df['opportunity_score'].mean()\n",
    "high_score_jobs = (jobs_df['opportunity_score'] >= 70).sum()\n",
    "\n",
    "print(f\"\\nðŸ“Š SCORING SUMMARY:\")\n",
    "print(f\"   â€¢ Average opportunity score: {avg_score:.1f}\")\n",
    "print(f\"   â€¢ High-value jobs (70+ score): {high_score_jobs}\")\n",
    "print(f\"   â€¢ Top score achieved: {jobs_df['opportunity_score'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways & Next Steps\n",
    "\n",
    "This job search automation demonstrates several powerful techniques:\n",
    "\n",
    "### ðŸ”§ Technical Implementation\n",
    "- **API Integration**: Serper API for automated job board searching\n",
    "- **Data Processing**: Pandas for deduplication and analysis\n",
    "- **Trend Analysis**: Time-series analysis of job market patterns\n",
    "- **Scoring Algorithms**: Automated opportunity ranking\n",
    "\n",
    "### ðŸ“Š Real-World Results\n",
    "- **628 unique job URLs** tracked across major job boards\n",
    "- **Daily trend monitoring** to identify posting patterns\n",
    "- **Application tracking** with status management\n",
    "- **Market intelligence** for strategic job searching\n",
    "\n",
    "### ðŸš€ Automation Benefits\n",
    "- **Time savings**: Automated discovery vs manual searching\n",
    "- **Market insights**: Data-driven job search strategy\n",
    "- **Opportunity ranking**: Focus on highest-value positions\n",
    "- **Trend tracking**: Understand market demand shifts\n",
    "\n",
    "**Tech Stack**: Python, Pandas, Plotly, Serper API, Selenium, BeautifulSoup"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}